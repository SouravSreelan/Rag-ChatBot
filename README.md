# ğŸ“„ RAG Chatbot with PDF Upload in Google Colab

This project is a simple **Retrieval-Augmented Generation (RAG)** chatbot built in **Google Colab** that lets you upload a PDF file, extract its content, and ask questions about it. It uses Google's **Gemini** models for embeddings and content generation. 

---
  
## âœ¨ Features  

- ğŸ“„ **PDF Upload**: Easily upload a PDF directly in Colab.
- ğŸ§  **Embedding with Gemini**: Each chunk of the document is vectorized using Googleâ€™s `embedding-001` model. 
- ğŸ” **Semantic Search**: Retrieve the most relevant chunks using FAISS.
- ğŸ’¬ **Ask Anything**: Ask questions, and get context-aware answers generated by Geminiâ€™s `gemini-1.5-flash` model. 

---

## ğŸ§‘â€ğŸ’» How it Works

1. **Upload PDF**  
   Use Google Colabâ€™s `files.upload()` to upload any PDF file.  

2. **Text Extraction**  
   The entire PDF is read and converted into raw text using `pypdf`.   

3. **Chunking**   
   The text is split into manageable chunks (default 500 characters) to enable effective retrieval.

4. **Embeddings Generation**  
   Each chunk is converted into an embedding using Geminiâ€™s embedding model.

5. **Indexing with FAISS**  
   All embeddings are indexed using **FAISS** for fast nearest-neighbor search.

6. **Retrieval + Generation**  
   - When you ask a question, the bot finds the top 3 most relevant chunks.
   - It then passes these chunks as context to Geminiâ€™s `gemini-1.5-flash` to generate an accurate answer.   

---


